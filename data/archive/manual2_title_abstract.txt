Verified in batches.

https://arxiv.org/abs/2509.10872
https://www.nature.com/articles/s41597-020-00746-1
https://www.nature.com/articles/s41597-021-00833-x
https://www.nature.com/articles/s41597-024-04247-3
https://www.nature.com/articles/s43588-023-00437-y
https://www.raco.cat/index.php/afinidad/article/view/432728
https://academic.oup.com/nar/article/49/D1/D562/5934416
https://academic.oup.com/nar/article/52/D1/D1180/7337608
https://chemrxiv.org/engage/chemrxiv/article-details/661697e091aefa6ce142c9d8
https://chemrxiv.org/engage/chemrxiv/article-details/661697e091aefa6ce142c9d8
https://setac.onlinelibrary.wiley.com/doi/10.1002/etc.5324
https://pubs.rsc.org/en/content/articlelanding/2017/cp/c7cp04913g
https://pubs.acs.org/doi/10.1021/jacs.2c01768
https://www.nature.com/articles/s41597-024-04051-z
https://www.nature.com/articles/s41597-022-01882-6
https://arxiv.org/abs/2410.0893
https://pubs.acs.org/doi/10.1021/acs.jcim.3c01211
https://pubs.acs.org/doi/10.1021/jm048957q
https://academic.oup.com/nar/article/52/D1/D1180/7337608
https://pubs.acs.org/doi/10.1021/acsomega.2c04856
https://pubs.rsc.org/en/content/articlelanding/2024/sc/d3sc03468b
https://www.nature.com/articles/s41597-024-04051-z
https://pubs.acs.org/doi/10.1021/acs.jpclett.9b02577
https://pubs.acs.org/doi/10.1021/acs.jpclett.4c01649
https://pubs.acs.org/doi/10.1021/acs.jpcc.4c06826
https://www.nature.com/articles/s41597-021-00798-x
https://pubs.rsc.org/en/content/articlelanding/2024/dd/d4dd00196f
https://www.nature.com/articles/npjcompumats201510
https://pubs.rsc.org/en/content/articlelanding/2017/cp/c7cp04913g
https://www.nature.com/articles/s41597-022-01529-6
https://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0384-1
https://doi.org/10.5281/zenodo.10257363
https://doi.org/10.5281/zenodo.13712924
https://pubmed.ncbi.nlm.nih.gov/39373710/
https://pubs.acs.org/doi/10.1021/acs.jcim.1c00007
https://arxiv.org/abs/2411.19629
https://arxiv.org/abs/2309.17311
https://pubs.acs.org/doi/full/10.1021/acs.jctc.3c00861
https://openaccess.thecvf.com/content/CVPR2022/html/Ren_DiLiGenT102_A_Photometric_Stereo_Benchmark_Dataset_With_Controlled_Shape_and_CVPR_2022_paper.html - "DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation"
https://ieeexplore.ieee.org/abstract/document/8972912 - "Multi-View Photometric Stereo: A Robust Solution and Benchmark Dataset for Spatially Varying Isotropic Materials"
https://doi.org/10.1016/j.dib.2021.107262 - "Benchmark datasets incorporating diverse tasks, sample sizes, material systems, and data heterogeneity for materials informatics"
https://doi.org/10.1063/5.0133528 - "Materials property prediction with uncertainty quantification: A benchmark study"
https://link.springer.com/article/10.1007/s40192-020-00174-4 - "Benchmark AFLOW Data Sets for Machine Learning"
https://doi.org/10.1016/j.eml.2020.100659 - "Mechanical MNIST: A benchmark dataset for mechanical metamodels"
https://pubs.rsc.org/en/content/articlehtml/2018/me/c8me00012c - "Can machine learning identify the next high-temperature superconductor? Examining extrapolation performance for materials discovery"
https://arxiv.org/abs/2206.13578 - "Materials Transformers Language Models for Generative Materials Design: a benchmark study"
https://link.springer.com/article/10.1186/s13059-023-03048-y - "Quartet protein reference materials and datasets for multi-platform assessment of label-free proteomics"
https://www.sciencedirect.com/science/article/pii/S0927025619304549 - "Machine learning models for the lattice thermal conductivity prediction of inorganic materials"
https://doi.org/10.1016/j.dib.2023.109487 - "Materials science optimization benchmark dataset for multi-objective, multi-fidelity optimization of hard-sphere packing simulations"
https://doi.org/10.1016/j.actamat.2017.11.053 - "Material structure-property linkages using three-dimensional convolutional neural networks"
https://www.nature.com/articles/s41524-021-00554-0 - "Benchmarking graph neural networks for materials chemistry"https://pubs.acs.org/doi/full/10.1021/acs.jcim.1c01031
https://pubs.acs.org/doi/full/10.1021/acs.jcim.4c01472
https://doi.org/10.26434/chemrxiv-2024-2p7ch
https://www.nature.com/articles/s41586-024-08127-z
https://arxiv.org/abs/2410.19316
https://pubs.rsc.org/en/content/articlelanding/2025/sc/d4sc06640e
https://pubs.rsc.org/en/content/articlelanding/2023/ma/d2ma01088g
https://www.sciencedirect.com/science/article/pii/S000925092500051X

{"title": "Reactive Chemistry at Unrestricted Coupled Cluster Level: High-throughput Calculations for Training Machine Learning Potentials", "abstract": "Accurately modeling chemical reactions at the atomistic level requires high-level electronic structure theory due to the presence of unpaired electrons and the need to properly describe bond breaking and making energetics. Commonly used approaches such as Density Functional Theory (DFT) frequently fail for this task due to deficiencies that are well recognized. However, for high-fidelity approaches, creating large datasets of energies and forces for reactive processes to train machine learning interatomic potentials or force fields is daunting. For example, the use of the unrestricted coupled cluster level of theory has previously been seen as unfeasible due to high computational costs, the lack of analytical gradients in many computational codes, and additional challenges such as constructing suitable basis set corrections for forces. In this work, we develop new methods and workflows to overcome the challenges inherent to automating unrestricted coupled cluster calculations. Using these advancements, we create a dataset of gas-phase reactions containing energies and forces for 3119 different organic molecules configurations calculated at the gold-standard level of unrestricted CCSD(T) (coupled cluster singles doubles and perturbative triples). With this dataset, we provide an analysis of the differences between the density functional and unrestricted CCSD(T) descriptions. We develop a transferable machine learning interatomic potential for gas-phase reactions, trained on unrestricted CCSD(T) data, and demonstrate the advantages of transitioning away from DFT data. Transitioning from training to DFT to training to UCCSD(T) datasets yields an improvement of more than 0.1 eV/Å in force accuracy and over 0.1 eV in activation energy reproduction."}
{"title": "QM-symex, update of the QM-sym database with excited state information for 173 kilo molecules", "abstract": "In the research field of material science, quantum chemistry database plays an indispensable role in determining the structure and properties of new material molecules and in deep learning in this field. A new quantum chemistry database, the QM-sym, has been set up in our previous work. The QM-sym is an open-access database focusing on transition states, energy, and orbital symmetry. In this work, we put forward the QM-symex with 173-kilo molecules. Each organic molecular in the QM-symex combines with the Cnh symmetry composite and contains the information of the first ten singlet and triplet transitions, including energy, wavelength, orbital symmetry, oscillator strength, and other quasi-molecular properties. QM-symex serves as a benchmark for quantum chemical machine learning models that can be effectively used to train new models of excited states in the quantum chemistry region as well as contribute to further development of the green energy revolution and materials discovery."}
{"title": "Quantum chemical benchmark databases of gold-standard dimer interaction energies", "abstract": "Advances in computational chemistry create an ongoing need for larger and higher-quality datasets that characterize noncovalent molecular interactions. We present three benchmark collections of quantum mechanical data, covering approximately 3,700 distinct types of interacting molecule pairs. The first collection, which we refer to as DES370K, contains interaction energies for more than 370,000 dimer geometries. These were computed using the coupled-cluster method with single, double, and perturbative triple excitations [CCSD(T)], which is widely regarded as the gold-standard method in electronic structure theory. Our second benchmark collection, a core representative subset of DES370K called DES15K, is intended for more computationally demanding applications of the data. Finally, DES5M, our third collection, comprises interaction energies for nearly 5,000,000 dimer geometries; these were calculated using SNS-MP2, a machine learning approach that provides results with accuracy comparable to that of our coupled-cluster training data. These datasets may prove useful in the development of density functionals, empirically corrected wavefunction-based approaches, semi-empirical methods, force fields, and models trained using machine learning methods."}
{"title": "QeMFi: A Multifidelity Dataset of Quantum Chemical Properties of Diverse Molecules", "abstract": "Progress in both Machine Learning (ML) and Quantum Chemistry (QC) methods have resulted in high accuracy ML models for QC properties. Datasets such as MD17 and WS22 have been used to benchmark these models at a given level of QC method, or fidelity, which refers to the accuracy of the chosen QC method. Multifidelity ML (MFML) methods, where models are trained on data from more than one fidelity, have shown to be effective over single fidelity methods. Much research is progressing in this direction for diverse applications ranging from energy band gaps to excitation energies. One hurdle for effective research here is the lack of a diverse multifidelity dataset for benchmarking. We provide the Quantum chemistry MultiFidelity (QeMFi) dataset consisting of five fidelities calculated with the TD-DFT formalism. The fidelities differ in their basis set choice: STO-3G, 3-21G, 6-31G, def2-SVP, and def2-TZVP. QeMFi offers to the community a variety of QC properties such as vertical excitation properties and molecular dipole moments. Further QeMFi offers QC computation times allowing for a time benefit benchmark of multifidelity models for ML-QC."}
{"title": "Fast evaluation of the adsorption energy of organic molecules on metals via graph neural networks", "abstract": "Modeling in heterogeneous catalysis requires the extensive evaluation of the energy of molecules adsorbed on surfaces. This is done via density functional theory but for large organic molecules it requires enormous computational time, compromising the viability of the approach. Here we present GAME-Net, a graph neural network to quickly evaluate the adsorption energy. GAME-Net is trained on a well-balanced chemically diverse dataset with C1–4 molecules with functional groups including N, O, S and C6–10 aromatic rings. The model yields a mean absolute error of 0.18 eV on the test set and is 6 orders of magnitude faster than density functional theory. Applied to biomass and plastics (up to 30 heteroatoms), adsorption energies are predicted with a mean absolute error of 0.016 eV per atom. The framework represents a tool for the fast screening of catalytic materials, particularly for systems that cannot be simulated by traditional methods."}
{"title": "Modelling and prediction of the thermal conductivity of ionic liquid using flaml as an automated machine learning approach", "abstract": "This manuscript reports the development of models using Microsoft’s library FLAML as automated machine learning approach to predict the behavior of thermal conductivity for ionic liquids. The models were obtained using an automated machine learning approach, the group contribution principle and Kernel Ridge Regression. A total of 990 experimental thermal conductivity data points for 81 ionic liquids were used to develop and compare the performance of 3 models. The results showed that the tested models calculated the thermal conductivity of ionic liquids with MAPE values lower than 2% for used database. The model trained with a split of 60/40 for training and test datasets respectively, showed the best performance for the prediction of the thermal conductivity of these compounds which points out at a good generalization capacity."}
{"title": "KLIFS: an overhaul after the first 5 years of supporting kinase research", "abstract": "Kinases are a prime target of drug development efforts with >60 drug approvals in the past two decades. Due to the research into this protein family, a wealth of data has been accumulated that keeps on growing. KLIFS—Kinase-Ligand Interaction Fingerprints and Structures—is a structural database focusing on how kinase inhibitors interact with their targets. The aim of KLIFS is to support (structure-based) kinase research through the systematic collection, annotation, and processing of kinase structures. Now, 5 years after releasing the initial KLIFS website, the database has undergone a complete overhaul with a new website, new logo, and new functionalities. In this article, we start by looking back at how KLIFS has been used by the research community, followed by a description of the renewed KLIFS, and conclude with showcasing the functionalities of KLIFS."}
{"title": "The ChEMBL Database in 2023: a drug discovery platform spanning multiple bioactivity data types and time periods", "abstract": "ChEMBL is a manually curated, high-quality, large-scale, open, FAIR and Global Core Biodata Resource of bioactive molecules with drug-like properties, previously described in the 2012, 2014, 2017 and 2019 Nucleic Acids Research Database Issues. Since its introduction in 2009, ChEMBL’s content has changed dramatically in size and diversity of data types. Here, we describe the ChEMBL Database in 2023 and its role as a platform for drug discovery, highlighting major additions and improvements, including expanded coverage of bioactivity data types, historical assay data, and integration with other resources. We also discuss data standards, quality assurance, and the provision of programmatic access for the community."}
{"title": "Guided docking as a data generation approach facilitates structure-based machine learning on kinases", "abstract": "Drug discovery pipelines nowadays rely on machine learning models to explore and evaluate large chemical spaces. While including 3D structural information is considered beneficial, structural models are hindered by the availability of protein–ligand complex structures. Exemplified for kinase drug discovery, we address this issue by generating kinase–ligand complex data using template docking for the kinase compound subset of available ChEMBL assay data. To evaluate the benefit of the created complex data, we use it to train a structure-based E(3)-invariant graph neural network (GNN). Our evaluation shows that binding affinities can be predicted with significantly higher precision by models that take synthetic binding poses into account compared to ligand or DTI models only."}
{"title": "Guided docking as a data generation approach facilitates structure-based machine learning on kinases", "abstract": "Drug discovery pipelines nowadays rely on machine learning models to explore and evaluate large chemical spaces. While including 3D structural information is considered beneficial, structural models are hindered by the availability of protein–ligand complex structures. Exemplified for kinase drug discovery, we address this issue by generating kinase–ligand complex data using template docking for the kinase compound subset of available ChEMBL assay data. To evaluate the benefit of the created complex data, we use it to train a structure-based E(3)-invariant graph neural network (GNN). Our evaluation shows that binding affinities can be predicted with significantly higher precision by models that take synthetic binding poses into account compared to ligand or DTI models only."}
{"title": "The ECOTOXicology Knowledgebase: A Curated Database of Ecologically Relevant Toxicity Tests to Support Environmental Research and Risk Assessment", "abstract": "The need for assembled existing and new toxicity data has accelerated as the amount of chemicals introduced into commerce continues to grow and regulatory mandates require safety assessments for a greater number of chemicals. To address this evolving need, the ECOTOXicology Knowledgebase (ECOTOX) was developed starting in the 1980s and is currently the world’s largest compilation of curated ecotoxicity data, providing support for assessments of chemical safety and ecological research through systematic and transparent literature review procedures. The recently released version of ECOTOX (Ver 5, www.epa.gov/ecotox) provides single-chemical ecotoxicity data for over 12,000 chemicals and ecological species with over one million test results from over 50,000 references. Presented is an overview of ECOTOX, detailing the literature review and data curation processes within the context of current systematic review practices and discussing how recent updates improve the accessibility and reusability of data to support the assessment, management, and research of environmental chemicals. Relevant and acceptable toxicity results are identified from studies in the scientific literature, with pertinent methodological details and results extracted following well-established controlled vocabularies and newly extracted toxicity data added quarterly to the public website. Release of ECOTOX, Ver 5, included an entirely redesigned user interface with enhanced data queries and retrieval options, visualizations to aid in data exploration, customizable outputs for export and use in external applications, and interoperability with chemical and toxicity databases and tools. This is a reliable source of curated ecological toxicity data for chemical assessments and research and continues to evolve with accessible and transparent state-of-the-art practices in literature data curation and increased interoperability to other relevant resources."}
{"title": "A look at the density functional theory zoo with the advanced GMTKN55 database for general main group thermochemistry, kinetics and noncovalent interactions", "abstract": "We present the GMTKN55 benchmark database for general main group thermochemistry, kinetics and noncovalent interactions. Compared to its popular predecessor GMTKN30 [Goerigk and Grimme J. Chem. Theory Comput., 2011, 7, 291], it allows assessment across a larger variety of chemical problems—with 13 new benchmark sets being presented for the first time—and it also provides reference values of significantly higher quality for most sets. GMTKN55 comprises 1505 relative energies based on 2462 single-point calculations and it is accessible to the user community via a dedicated website. Herein, we demonstrate the importance of better reference values, and we re-emphasise the need for London-dispersion corrections in density functional theory (DFT) treatments of thermochemical problems, including Minnesota methods. We assessed 217 variations of dispersion-corrected and -uncorrected density functional approximations, and carried out a detailed analysis of 83 of them to identify robust and reliable approaches. Double-hybrid functionals are the most reliable approaches for thermochemistry and noncovalent interactions, and they should be used whenever technically feasible. These are, in particular, DSD-BLYP-D3(BJ), DSD-PBEP86-D3(BJ), and B2GPPLYP-D3(BJ). The best hybrids are ωB97X-V, M052X-D3(0), and ωB97X-D3, but we also recommend PW6B95-D3(BJ) as the best conventional global hybrid. At the meta-generalised-gradient (meta-GGA) level, the SCAN-D3(BJ) method can be recommended. Other meta-GGAs are outperformed by the GGA functionals revPBE-D3(BJ), B97-D3(BJ), and OLYP-D3(BJ). We note that many popular methods, such as B3LYP, are not part of our recommendations. In fact, with our results we hope to inspire a change in the user community’s perception of common DFT methods. We also encourage method developers to use GMTKN55 for cross-validation studies of new methodologies."}
{"title": "Predicting Solubility Limits of Organic Solutes for a Wide Range of Solvents and Temperatures", "abstract": "The solubility of organic molecules is crucial in organic synthesis and industrial chemistry; it is important in the design of many phase separation and purification units, and it controls the migration of many species into the environment. To decide which solvents and temperatures can be used in the design of new processes, trial and error is often used, as the choice is restricted by unknown solid solubility limits. Here, we present a fast and convenient computational method for estimating the solubility of solid neutral organic molecules in water and many organic solvents for a broad range of temperatures. The model is developed by combining fundamental thermodynamic equations with machine learning models for solvation free energy, solvation enthalpy, Abraham solute parameters, and aqueous solid solubility at 298 K. We provide free open-source and online tools for the prediction of solid solubility limits and a curated data collection (SolProp) that includes more than 5000 experimental solid solubility values for validation of the model. The model predictions are accurate for aqueous systems and for a huge range of organic solvents up to 550 K or higher. Methods to further improve solid solubility predictions by providing experimental data on the solute of interest in another solvent, or on the solute’s sublimation enthalpy, are also presented."}
{"title": "Pyrfume: A window to the world’s olfactory data", "abstract": "Advances in theoretical understanding are frequently unlocked by access to large, diverse experimental datasets. Our understanding of olfactory neuroscience and psychophysics remain years behind the other senses, in part because rich datasets linking olfactory stimuli with their corresponding percepts, behaviors, and neural pathways remain scarce. Here we present a concerted effort to unlock and unify dozens of stimulus-linked olfactory datasets across species and modalities under a unified framework called Pyrfume. We present examples of how researchers might use Pyrfume to conduct novel analyses uncovering new principles, introduce trainees to the field, or construct benchmarks for machine olfaction."}
{"title": "SPICE, A Dataset of Drug-like Molecules and Peptides for Training Machine Learning Potentials", "abstract": "Machine learning potentials are an important tool for molecular simulation, but their development is held back by a shortage of high quality datasets to train them on. We describe the SPICE dataset, a new quantum chemistry dataset for training potentials relevant to simulating drug-like small molecules interacting with proteins. It contains over 1.1 million conformations for a diverse set of small molecules, dimers, dipeptides, and solvated amino acids. It includes 15 elements, charged and uncharged molecules, and a wide range of covalent and non-covalent interactions. It provides both forces and energies calculated at the ωB97M-D3(BJ)/def2-TZVPPD level of theory, along with other useful quantities such as multipole moments and bond orders. We train a set of machine learning potentials on it and demonstrate that they can achieve chemical accuracy across a broad region of chemical space. It can serve as a valuable resource for the creation of transferable, ready to use potential functions for use in molecular simulations."}
{"title": "The quantum trajectory sensing problem and its solution", "abstract": "The quantum trajectory sensing problem seeks quantum sensor states which enable the trajectories of incident particles to be distinguished using a single measurement. For an n-qubit sensor state to unambiguously discriminate a set of trajectories with a single projective measurement, all post-trajectory output states must be mutually orthogonal; therefore, the 2^n state coefficients must satisfy a system of constraints which is typically very large. Given that this system is generally challenging to solve directly, we introduce a group-theoretic framework which simplifies the criteria for sensor states and exponentially reduces the number of equations and variables involved when the trajectories obey certain symmetries. These simplified criteria yield general families of trajectory sensor states and provide bounds on the particle–sensor interaction strength required for perfect one-shot trajectory discrimination. Furthermore, we establish a link between trajectory sensing and quantum error correction, recognizing their common motivation to identify perturbations using projective measurements. Our sensor states in fact form novel quantum codes, and conversely, a number of familiar stabilizer codes (such as toric codes) also provide trajectory sensing capabilities. This connection enables noise-resilient trajectory sensing through the concatenation of sensor states with quantum error-correcting codes."}
{"title": "BigBind: Learning from Nonstructural Data for Structure-Based Virtual Screening", "abstract": "Deep learning methods that predict protein-ligand binding have recently been used for structure-based virtual screening. Many such models have been trained using protein-ligand complexes with known crystal structures and activities from the PDBBind data set. However, because PDBbind only includes 20K complexes, models typically fail to generalize to new targets, and model performance is on par with models trained with only ligand information. Conversely, the ChEMBL database contains a wealth of chemical activity information but includes no information about binding poses. We introduce BigBind, a data set that maps ChEMBL activity data to proteins from the CrossDocked data set. BigBind comprises 583 K ligand activities and includes 3D structures of the protein binding pockets. Additionally, we augmented the data by adding an equal number of putative inactives for each target. Using this data, we developed Banana (basic neural network for binding affinity), a neural network-based model to classify active from inactive compounds, defined by a 10 μM cutoff. Our model achieved an AUC of 0.72 on BigBind's test set, while a ligand-only model achieved an AUC of 0.59. Furthermore, Banana achieved competitive performance on the LIT-PCBA benchmark (median EF1% 1.81) while running 16,000 times faster than molecular docking with Gnina. We suggest that Banana, as well as other models trained on this data set, will significantly improve the outcomes of prospective virtual screening tasks."}
{"title": "The PDBbind database: methodologies and updates", "abstract": "We have developed the PDBbind database to provide a comprehensive collection of binding affinities for the protein-ligand complexes in the Protein Data Bank (PDB). This paper gives a full description of the latest version, i.e., version 2003, which is an update to our recently reported work. Out of 23 790 entries in the PDB release No.107 (January 2004), 5897 entries were identified as protein-ligand complexes that meet our definition. Experimentally determined binding affinities (K(d), K(i), and IC(50)) for 1622 of these were retrieved from the references associated with these complexes. A total of 900 complexes were selected to form a \"refined set\", which is of particular value as a standard data set for docking and scoring studies. All of the final data, including binding affinity data, reference citations, and processed structural files, have been incorporated into the PDBbind database accessible on-line at http:// www.pdbbind.org/."}
{"title": "The ChEMBL Database in 2023: a drug discovery platform spanning multiple bioactivity data types and time periods", "abstract": "ChEMBL (https://www.ebi.ac.uk/chembl/) is a manually curated, high-quality, large-scale, open, FAIR and Global Core Biodata Resource of bioactive molecules with drug-like properties, previously described in the 2012, 2014, 2017 and 2019 Nucleic Acids Research Database Issues. Since its introduction in 2009, ChEMBL's content has changed dramatically in size and diversity of data types. Through incorporation of multiple new datasets from depositors since the 2019 update, ChEMBL now contains slightly more bioactivity data from deposited data vs data extracted from literature. In collaboration with the EUbOPEN consortium, chemical probe data is now regularly deposited into ChEMBL. Release 27 made curated data available for compounds screened for potential anti-SARS-CoV-2 activity from several large-scale drug repurposing screens. In addition, new patent bioactivity data have been added to the latest ChEMBL releases, and various new features have been incorporated, including a Natural Product likeness score, updated flags for Natural Products, a new flag for Chemical Probes, and the initial annotation of the action type for ∼270 000 bioactivity measurements."}
{"title": "Predicting Synthesizability using Machine Learning on Databases of Existing Inorganic Materials", "abstract": "Defining the metric for synthesizability and predicting new compounds that can be experimentally realized in the realm of data-driven research is a pressing problem in contemporary materials science. The increasing computational power and advancements in machine learning (ML) algorithms provide a new avenue to solve the synthesizability challenge. In this work, using the Inorganic Crystal Structure Database (ICSD) and the Materials Project (MP) database, we represent crystal structures in Fourier-transformed crystal properties (FTCP) representation and use a deep learning model to predict synthesizability in the form of a synthesizability score (SC). Such an SC model, as a synthesizability filter for new materials, enables an efficient and accurate classification to identify promising material candidates. The SC prediction model achieved 82.6/80.6% (precision/recall) overall accuracy in predicting ternary crystal materials. We also trained the SC model by only considering compounds uploaded on the MP before 2015 as the training set and testing on multiple sets of materials uploaded after 2015. In the post-2019 test set, we obtain a high 88.60% true positive rate accuracy, coupled with 9.81% precision, indicating that newly added materials remain unexplored and have high synthesis potential. Further, we provide a list of 100 materials predicted to be synthesizable from this post-2019 dataset (highest SC) for future studies, and our SC model, as a validation filter, is beneficial for future material screening and discovery."}
{"title": "Designing solvent systems using self-evolving solubility databases and graph neural networks", "abstract": "Designing solvent systems is key to achieving the facile synthesis and separation of desired products from chemical processes, so many machine learning models have been developed to predict solubilities. However, breakthroughs are needed to address deficiencies in the model's predictive accuracy and generalizability; this can be addressed by expanding and integrating experimental and computational solubility databases. To maximize predictive accuracy, these two databases should not be trained separately, and they should not be simply combined without reconciling the discrepancies from different magnitudes of errors and uncertainties. Here, we introduce self-evolving solubility databases and graph neural networks developed through semi-supervised self-training approaches. Solubilities from quantum-mechanical calculations are referred to during semi-supervised learning, but they are not directly added to the experimental database. Dataset augmentation is performed from 11 637 experimental solubilities to >900 000 data points in the integrated database, while correcting for the discrepancies between experiment and computation. Our model was successfully applied to study solvent selection in organic reactions and separation processes. The accuracy (mean absolute error around 0.2 kcal mol−1 for the test set) is quantitatively useful in exploring Linear Free Energy Relationships between reaction rates and solvation free energies for 11 organic reactions. Our model also accurately predicted the partition coefficients of lignin-derived monomers and drug-like molecules. While there is room for expanding solubility predictions to transition states, radicals, charged species, and organometallic complexes, this approach will be attractive to predictive chemistry areas where experimental, computational, and other heterogeneous data should be combined."}
{"title": "Pyrfume: A window to the world’s olfactory data", "abstract": "Advances in theoretical understanding are frequently unlocked by access to large, diverse experimental datasets. Our understanding of olfactory neuroscience and psychophysics remain years behind the other senses, in part because rich datasets linking olfactory stimuli with their corresponding percepts, behaviors, and neural pathways remain scarce. Here we present a concerted effort to unlock and unify dozens of stimulus-linked olfactory datasets across species and modalities under a unified framework called Pyrfume. We present examples of how researchers might use Pyrfume to conduct novel analyses uncovering new principles, introduce trainees to the field, or construct benchmarks for machine olfaction."}
{"title": "Virtual Excited State Reference for the Discovery of Electronic Materials Database: An Open-Access Resource for Ground and Excited State Properties of Organic Molecules", "abstract": "This letter announces the Virtual Excited State Reference for the Discovery of Electronic Materials Database (VERDE materials DB), the first database to include downloadable excited-state structures (S0, S1, T1) and photophysical properties. VERDE materials DB is searchable, open-access via www.verdedb.org , and focused on light-responsive π-conjugated organic molecules with applications in green chemistry, organic solar cells, and organic redox flow batteries. It includes results of our active and past virtual screening studies; to date, more than 13 000 density functional theory (DFT) calculations have been performed on 1 500 molecules to obtain frontier molecular orbitals and photophysical properties, including excitation energies, dipole moments, and redox potentials. To improve community access, we have made VERDE materials DB available via an integration with the Materials Data Facility. We are leveraging VERDE materials DB to train machine learning algorithms to identify new materials and structure-property relationships between molecular ground- and excited-states. We present a case-study involving photoaffinity labels, including predictions of new diazirine-based photoaffinity labels anticipated to have high photostabilities."}
{"title": "ΔDFT Predicts Inverted Singlet-Triplet Gaps with Chemical Accuracy at a Fraction of the Cost of Wave Function-Based Approaches", "abstract": "Efficient OLEDs need to quickly convert singlet and triplet excitons into photons. Molecules with an inverted singlet-triplet energy gap (INVEST) are promising candidates for this task. However, typical INVEST molecules have drawbacks like too low oscillator strengths and excitation energies. High-throughput screening could identify suitable INVEST molecules, but existing methods are problematic: The workhorse method TD-DFT cannot reproduce gap inversion, while wave function-based methods are too slow. This study proposes a state-specific method based on unrestricted Kohn-Sham DFT with common hybrid functionals. Tuned on the new INVEST15 benchmark set, this method achieves an error of less than 1 kcal/mol, which is traced back to error cancellation between spin contamination and dynamic correlation. Applied to the larger and structurally diverse NAH159 set in a black-box fashion, the method maintains a small error (1.2 kcal/mol) and accurately predicts gap signs in 83% of cases, confirming its robustness and suitability for screening workflows."}
{"title": "BEAST DB: Grand-Canonical Database of Electrocatalyst Properties", "abstract": "We present BEAST DB, an open-source database comprised of ab initio electrochemical data computed using grand-canonical density functional theory in implicit solvent at consistent calculation parameters. The database contains over 20,000 surface calculations and covers a broad set of heterogeneous catalyst materials and electrochemical reactions. Calculations were performed at self-consistent fixed potential as well as constant charge to facilitate comparisons to the computational hydrogen electrode. This article presents common use cases of the database to rationalize trends in catalyst activity, screen catalyst material spaces, understand elementary mechanistic steps, analyze the electronic structure, and train machine learning models to predict higher fidelity properties. Users can interact graphically with the database by querying for individual calculations to gain a granular understanding of reaction steps or by querying for an entire reaction pathway on a given material using an interactive reaction pathway tool. BEAST DB will be periodically updated, with planned future updates to include advanced electronic structure data, surface speciation studies, and greater reaction coverage."}
{"title": "A database framework for rapid screening of structure-function relationships in PFAS chemistry", "abstract": "This paper describes a database framework that enables one to rapidly explore systematics in structure-function relationships associated with new and emerging PFAS chemistries. The data framework maps high dimensional information associated with the SMILES approach of encoding molecular structure with functionality data including bioactivity and physicochemical property. This ‘PFAS-Map’ is a 3-dimensional unsupervised visualization tool that can automatically classify new PFAS chemistries based on current PFAS classification criteria. We provide examples on how the PFAS-Map can be utilized, including the prediction and estimation of yet unmeasured fundamental physical properties of PFAS chemistries, uncovering hierarchical characteristics in existing classification schemes, and the fusion of data from diverse sources."}
{"title": "Polyuniverse: generation of a large-scale polymer library using rule-based polymerization reactions for polymer informatics", "abstract": "Recent advancements in machine learning have revolutionized polymer research, leading to the swift integration of diverse computational techniques for de novo molecular design. A crucial aspect of these processes is to expand the number of candidate polymer structures, as the currently known real polymer structures are very limited. In contrast, small molecule databases are vast, offering extensive opportunities for the design of new molecules, such as drug discovery. In this study, we collected extensive small molecule compounds from GDB-17, GDB-13, and PubChem and selected polymerization reaction pathways for eight types of polymers, including polyimide, polyolefin, polyester, polyamide, polyurethane, epoxy, polybenzimidazole (PBI), and vitrimer. These small molecule datasets and polymerization reactions enabled us to generate hundreds of quadrillions of hypothetical polymer structures. For each of the eight polymers, along with one promising copolymer, poly(imide-imine), we randomly generated over one million hypothetical structures, except for PBI, for which we created 10 000 structures. Chemical space visualization using t-distributed stochastic neighbor embedding and synthetic accessibility scores were employed to assess the feasibility of synthesizing these new polymers. Customized feedforward neural network models predicted thermal, mechanical, and gas permeation properties for both real and hypothetical polymers. The results show that many hypothetical polymers, especially polyimides, exhibit significant potential, often surpassing real polymers in performance, particularly for high-temperature applications and gas separation. Our findings highlight the immense potential of large-scale hypothetical polymer libraries for materials discovery and design. These libraries not only aid in identifying promising polymer materials through high-throughput screening but also provide valuable datasets for training advanced machine learning models, such as large language models. This research also demonstrates the power of data-driven approaches in polymer science, paving the way for the development of next-generation polymeric materials with superior properties for diverse industrial applications."}
{"title": "The Open Quantum Materials Database (OQMD): assessing the accuracy of DFT formation energies", "abstract": "The Open Quantum Materials Database (OQMD) is a high-throughput database currently consisting of nearly 300,000 density functional theory (DFT) total energy calculations of compounds from the Inorganic Crystal Structure Database (ICSD) and decorations of commonly occurring crystal structures. To maximise the impact of these data, the entire database is being made available, without restrictions, at www.oqmd.org/download. In this paper, we outline the structure and contents of the database, and then use it to evaluate the accuracy of the calculations therein by comparing DFT predictions with experimental measurements for the stability of all elemental ground-state structures and 1,670 experimental formation energies of compounds. This represents the largest comparison between DFT and experimental formation energies to date. The apparent mean absolute error between experimental measurements and our calculations is 0.096 eV/atom. In order to estimate how much error to attribute to the DFT calculations, we also examine deviation between different experimental measurements themselves where multiple sources are available, and find a surprisingly large mean absolute error of 0.082 eV/atom. Hence, we suggest that a significant fraction of the error between DFT and experimental formation energies may be attributed to experimental uncertainties. Finally, we evaluate the stability of compounds in the OQMD (including compounds obtained from the ICSD as well as hypothetical structures), which allows us to predict the existence of ~3,200 new compounds that have not been experimentally characterised and uncover trends in material discovery, based on historical data available within the ICSD."}
{"title": "A look at the density functional theory zoo with the advanced GMTKN55 database for general main group thermochemistry, kinetics and noncovalent interactions", "abstract": "We present the GMTKN55 benchmark database for general main group thermochemistry, kinetics and noncovalent interactions. Compared to its popular predecessor GMTKN30 [Goerigk and Grimme J. Chem. Theory Comput., 2011, 7, 291], it allows assessment across a larger variety of chemical problems—with 13 new benchmark sets being presented for the first time—and it also provides reference values of significantly higher quality for most sets. GMTKN55 comprises 1505 relative energies based on 2462 single-point calculations and it is accessible to the user community via a dedicated website. Herein, we demonstrate the importance of better reference values, and we re-emphasise the need for London-dispersion corrections in density functional theory (DFT) treatments of thermochemical problems, including Minnesota methods. We assessed 217 variations of dispersion-corrected and -uncorrected density functional approximations, and carried out a detailed analysis of 83 of them to identify robust and reliable approaches. Double-hybrid functionals are the most reliable approaches for thermochemistry and noncovalent interactions, and they should be used whenever technically feasible. These are, in particular, DSD-BLYP-D3(BJ), DSD-PBEP86-D3(BJ), and B2GPPLYP-D3(BJ). The best hybrids are ωB97X-V, M052X-D3(0), and ωB97X-D3, but we also recommend PW6B95-D3(BJ) as the best conventional global hybrid. At the meta-generalised-gradient (meta-GGA) level, the SCAN-D3(BJ) method can be recommended. Other meta-GGAs are outperformed by the GGA functionals revPBE-D3(BJ), B97-D3(BJ), and OLYP-D3(BJ). We note that many popular methods, such as B3LYP, are not part of our recommendations. In fact, with our results we hope to inspire a change in the user community's perception of common DFT methods. We also encourage method developers to use GMTKN55 for cross-validation studies of new methodologies."}
{"title": "High accuracy barrier heights, enthalpies, and rate coefficients for chemical reactions", "abstract": "Quantitative chemical reaction data, including activation energies and reaction rates, are crucial for developing detailed kinetic mechanisms and accurately predicting reaction outcomes. However, such data are often difficult to find, and high-quality datasets are especially rare. Here, we use CCSD(T)-F12a/cc-pVDZ-F12//ω B97X-D3/def2-TZVP to obtain high-quality single point calculations for nearly 22,000 unique stable species and transition states. We report the results from these quantum chemistry calculations and extract the barrier heights and reaction enthalpies to create a kinetics dataset of nearly 12,000 gas-phase reactions. These reactions involve H, C, N, and O, contain up to seven heavy atoms, and have cleaned atom-mapped SMILES. Our higher-accuracy coupled-cluster barrier heights differ significantly (RMSE of ∼5 kcal mol−1) relative to those calculated at ω B97X-D3/def2-TZVP. We also report accurate transition state theory rate coefficients {k_∞}(T) between 300 K and 2000 K and the corresponding Arrhenius parameters for a subset of rigid reactions. We believe this data will accelerate development of automated and reliable methods for quantitative reaction prediction."}
{"title": "Open-source QSAR models for pKa prediction using multiple machine learning approaches", "abstract": "Background: The logarithmic acid dissociation constant pKa reflects the ionization of a chemical, which affects lipophilicity, solubility, protein binding, and ability to pass through the plasma membrane. Thus, pKa affects chemical absorption, distribution, metabolism, excretion, and toxicity properties. Multiple proprietary software packages exist for the prediction of pKa, but to the best of our knowledge no free and open-source programs exist for this purpose. Using a freely available data set and three machine learning approaches, we developed open-source models for pKa prediction. Methods: The experimental strongest acidic and strongest basic pKa values in water for 7912 chemicals were obtained from DataWarrior, a freely available software package. Chemical structures were curated and standardized for quantitative structure–activity relationship (QSAR) modeling using KNIME, and a subset comprising 79% of the initial set was used for modeling. To evaluate different approaches to modeling, several datasets were constructed based on different processing of chemical structures with acidic and/or basic pKas. Continuous molecular descriptors, binary fingerprints, and fragment counts were generated using PaDEL, and pKa prediction models were created using three machine learning methods, (1) support vector machines (SVM) combined with k-nearest neighbors (kNN), (2) extreme gradient boosting (XGB) and (3) deep neural networks (DNN). Results: The three methods delivered comparable performances on the training and test sets with a root-mean-squared error (RMSE) around 1.5 and a coefficient of determination (R^2) around 0.80. Two commercial pKa predictors from ACD/Labs and ChemAxon were used to benchmark the three best models developed in this work, and performance of our models compared favorably to the commercial products. Conclusions: This work provides multiple QSAR models to predict the strongest acidic and strongest basic pKas of chemicals, built using publicly available data, and provided as free and open-source software on GitHub."}
{"title": "Data for 'Tensorial properties via the neuroevolution potential framework: Fast simulation of infrared and Raman spectra'", "abstract": "This Zenodo record provides trained neuroevolution potential (NEP) and tensor NEP (TNEP) models and companion training datasets for molecular water species, liquid water, and barium zirconate, usable with GPUMD 3.9. The archive includes parameter files (nep*.txt) and zipped datasets for dipole moments, polarizabilities, susceptibilities, and potential energy surfaces (e.g., water monomer/dimer/Zundel, QM7B subsets, bulk water, iron oxide, and BaZrO3). It enables fast simulations of tensorial properties—such as infrared and Raman spectra—within the NEP/TNEP framework."}
{"title": "Neuroevolution potential for aluminum", "abstract": "Open dataset releasing a neuroevolution potential (NEP) for elemental aluminum. The record contains an interatomic potential file (nep.txt) and an accompanying aluminum-CX database, intended for use with GPUMD. These resources support atomistic simulations of aluminum by providing a machine-learned potential and training data packaged for reproducible deployment."}
{"title": "Accurate Geometries of Large Molecules at DFT Cost by Semiexperimental and Coupled Cluster Templating Fragments", "abstract": "Accurate geometries of small semirigid molecules in the gas phase are available thanks to high-resolution spectroscopy and accurate quantum chemical approaches. These results can be employed for validating cheaper low-level quantum chemical models or correcting the corresponding structures of large molecules. On these grounds, in this work, a large panel of semiexperimental equilibrium structures already available in the literature is used to confirm the average error (1 mÅ for bond lengths and 2 mrad for valence angles) of a version of the Pisa composite schemes (PCS2), which is applicable to molecules containing up to about 20 atoms. Then, the geometries of 30 additional medium-sized systems were optimized at the PCS2 level to cover a more balanced chemical space containing moieties poorly represented in SE compilations. The final database is available on a public domain Web site (https://www.skies-village.it/databases/) and can be employed for correcting structures of larger molecules obtained by hybrid or double-hybrid density functionals in the framework of the templating molecule approach. Several examples show that corrections based on the structures of building blocks taken from this database reduce the error of the B3LYP geometrical parameters of large molecules by nearly an order of magnitude without increasing the computational cost. Furthermore, the results of different density functional theory (DFT) or wave function (e.g., MP2) models can be improved in the same way by simply computing both the whole molecule and suitable building blocks at the chosen level. Then, whenever reference structures of some building blocks containing up to about 20 atoms are not available, they can be purposely optimized at the PCS2 level by employing reasonable computer resources. Therefore, a new DFT-cost tool is now available for the accurate characterization of large molecules by experiment-oriented scientists."}
{"title": "Dataset Construction to Explore Chemical Space with 3D Geometry and Deep Learning", "abstract": "A dataset is the basis of deep learning model development, and the success of deep learning models heavily relies on the quality and size of the dataset. In this work, we present a new data preparation protocol and build a large fragment-based dataset Frag20, which consists of optimized 3D geometries and calculated molecular properties from Merck molecular force field (MMFF) and DFT at the B3LYP/6-31G* level of theory for more than half a million molecules composed of H, B, C, O, N, F, P, S, Cl, and Br with no larger than 20 heavy atoms. Based on the new dataset, we develop robust molecular energy prediction models using a simplified PhysNet architecture for both DFT-optimized and MMFF-optimized geometries, which achieve better than or close to chemical accuracy (1 kcal/mol) on multiple test sets, including CSD20 and Plati20 based on experimental crystal structures."}
{"title": "OpenQDC: Open Quantum Data Commons", "abstract": "Machine Learning Interatomic Potentials (MLIPs) are promising alternatives to classical force fields for molecular dynamics, but quantum-mechanical datasets needed for MLIPs are fragmented. OpenQDC consolidates 37 QM datasets (covering >250 quantum methods and ~400 million geometries) into a single, standardized resource with Python tooling for normalization and integration. Baselines with SchNet, TorchMD-Net, and DimeNet highlight current challenges and establish a leaderboard to spur benchmarking and model development. The project aims to democratize access to QM data and accelerate MLIP research."}
{"title": "Reference Vertical Excitation Energies for Transition Metal Compounds", "abstract": "To enrich and enhance the diversity of the QUEST database of highly-accurate excitation energies, we report vertical transition energies in transition metal compounds. Eleven diatomic molecules with singlet or doublet ground state containing a fourth-row transition metal (CuCl, CuF, CuH, ScF, ScH, ScO, ScS, TiN, ZnH, ZnO, and ZnS) are considered and the corresponding excitation energies are computed using high-level coupled-cluster (CC) methods, namely CC3, CCSDT, CC4, and CCSDTQ, as well as multiconfigurational methods such as CASPT2 and NEVPT2. In some cases, to provide more comprehensive benchmark data, we also provide full configuration interaction estimates computed with the \"Configuration Interaction using a Perturbative Selection made Iteratively\" (CIPSI) method. Based on these calculations, theoretical best estimates of the transition energies are established in both the aug-cc-pVDZ and aug-cc-pVTZ basis sets. This allows us to accurately assess the performance of CC and multiconfigurational methods for this specific set of challenging transitions. Furthermore, comparisons with experimental data and previous theoretical results are also reported."}
{"title": "Benchmark Data Set of Crystalline Organic Semiconductors", "abstract": "This work reports a Benchmark Data set of Crystalline Organic Semiconductors to test calculations of the structural and electronic properties of these materials in the solid state. The data set contains 67 crystals consisting of mostly rigid molecules with a single dominant conformer, covering the majority of known structural types. The experimental crystal structure is available for the entire data set, whereas zero-temperature unit cell volume can be reliably estimated for a subset of 28 crystals. Hence, the availability of a benchmark data set for organic semiconductors in their solid-state form is important for assessing the predictive capabilities of computational methods concerning the structural and electronic properties of these materials. This work is aimed to provide such a data set for single crystals, which not only incorporate the most appropriate structural morphology for this purpose but are also of practical use in optoelectronics. Over time, numerous large and small data sets of crystalline organic semiconductors have been accumulated; however, these data sets were not specifically designed for benchmarking purposes. Available benchmark data sets for molecular crystals and clusters do not contain sufficient samples of extended π-conjugated molecules commonly used in optoelectronic applications. Alternatively, crystals for benchmarking can be taken directly from the Cambridge Structural Database (CSD) or similar heterogeneous sources; however, practitioners should be aware of possible ambiguity in the preprocessing of the raw structural information before benchmarking. This work introduces the BMCOS1 data set (Benchmark Data set of Crystalline Organic Semiconductors part 1) containing 67 crystals, whose molecular structures are explicitly listed and curated in a unified form suitable for further analysis of electronic properties."}
{"title": "DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation", "abstract": "Evaluating photometric stereo using real-world datasets is important yet difficult. Existing datasets are insufficient due to their limited scale and random distributions in shape and material. This paper presents a new real-world photometric stereo dataset with “ground truth” normal maps, which is 10× larger than the widely adopted one. We systematically control shapes and materials to cover diverse geometry and BRDFs, and provide accurate ground-truth normals to enable rigorous evaluation. We further establish comprehensive experimental protocols and baselines to assess state-of-the-art methods, revealing strengths and limitations under controlled shape and material variation."}
{"title": "Multi-View Photometric Stereo: A Robust Solution and Benchmark Dataset for Spatially Varying Isotropic Materials", "abstract": "We present a method to capture both 3D shape and spatially varying reflectance with a multi-view photometric stereo (MVPS) technique that works for general isotropic materials. Our algorithm is suitable for perspective cameras and nearby point light sources. Our data capture setup is simple, which consists of only a digital camera, some LED lights, and an optional automatic turntable. From a single viewpoint, we use a set of photometric stereo images to identify surface points with the same distance to the camera. We collect this information from multiple viewpoints and combine it with structure-from-motion to obtain a precise reconstruction of the complete 3D shape. The spatially varying isotropic BRDF is captured by simultaneously inferring a set of basis BRDFs and their mixing weights at each surface point. In experiments, we demonstrate our algorithm with two different setups: a studio setup for highest precision and a desktop setup for best usability. According to our experiments, under the studio setting, the captured shapes are accurate to 0.5 mm and the captured reflectance has a relative RMSE of 9%. We also quantitatively evaluate state-of-the-art MVPS on a newly collected benchmark dataset, which is publicly available for inspiring future research."}
{"title": "Benchmark datasets incorporating diverse tasks, sample sizes, material systems, and data heterogeneity for materials informatics", "abstract": "The data contains both experimental and computational data, data suited for regression as well as classification, sizes ranging from 12 to 6354 samples, and materials systems spanning the diversity of materials research. Data were extracted from 16 publications. In addition to cleaning the data where necessary, each dataset was split into train, validation, and test splits. These benchmark datasets can be used to evaluate machine learning algorithms for materials informatics across a broad range of tasks while highlighting the effects of data heterogeneity, sample size, and system diversity."}
{"title": "Materials property prediction with uncertainty quantification: A benchmark study", "abstract": "Uncertainty quantification (UQ) has increasing importance in the building of robust high-performance and generalizable materials property prediction models. It can also be used in active learning to train better models by focusing on gathering new training data from uncertain regions. There are several categories of UQ methods each considering different types of uncertainty sources. Here we conduct a comprehensive evaluation on the UQ methods for graph neural network based materials property prediction and evaluate how they truly reflect the uncertainty that we want in error bound estimation or active learning. Our experimental results over four crystal materials datasets (including formation energy, adsorption energy, total energy, and band gap properties) show that the popular ensemble methods for uncertainty estimation is not the best choice for UQ in materials property prediction. For the convenience of the community, all the source code and datasets can be accessed freely."}
{"title": "Benchmark AFLOW Data Sets for Machine Learning", "abstract": "Materials informatics is increasingly finding ways to exploit machine learning algorithms. Techniques such as decision trees, ensemble methods, support vector machines, and a variety of neural network architectures are used to predict likely material characteristics and property values. Supplemented with laboratory synthesis, applications of machine learning to compound discovery and characterization represent one of the most promising research directions in materials informatics. A shortcoming of this trend, in its current form, is a lack of standardized materials data sets on which to train, validate, and test model effectiveness. Applied machine learning research depends on benchmark data to make sense of its results. Fixed, predetermined data sets allow for rigorous model assessment and comparison. Machine learning publications that do not refer to benchmarks are often hard to contextualize and reproduce. In this data descriptor article, we present a collection of data sets of different material properties taken from the AFLOW database. We describe them, the procedures that generated them, and their use as potential benchmarks. We provide a compressed ZIP file containing the data sets and a GitHub repository of associated Python code. Finally, we discuss opportunities for future work incorporating the data sets and creating similar benchmark collections."}
{"title": "Mechanical MNIST: A benchmark dataset for mechanical metamodels", "abstract": "We introduce a benchmark data set (Mechanical MNIST) for constructing metamodels of heterogeneous materials undergoing large deformation. Inspired by the MNIST dataset in computer vision, we convert 28×28 bitmap images into 2D heterogeneous blocks of a Neo-Hookean material and run 70,000 finite element simulations (60,000 train, 10,000 test) under large deformation. In addition to introducing this dataset, we provide baseline metamodels trained on the data and demonstrate their performance, establishing a standard reference for comparing methods on mechanically relevant problems."}
{"title": "Can machine learning identify the next high-temperature superconductor? Examining extrapolation performance for materials discovery", "abstract": "Traditional machine learning (ML) metrics overestimate model performance for materials discovery. We introduce (1) leave-one-cluster-out cross-validation (LOCO CV) and (2) a simple nearest-neighbor benchmark to show that model performance in discovery applications strongly depends on the problem, data sampling, and extrapolation. Our results suggest that ML-guided iterative experimentation may outperform standard high-throughput screening for discovering breakthrough materials like high-T_{c} superconductors with ML."}
{"title": "Materials Transformers Language Models for Generative Materials Design: a benchmark study", "abstract": "Pre-trained transformer language models on large unlabeled corpus have produced state-of-the-art results in natural language processing, organic molecule design, and protein sequence generation. However, no such models have been applied to learn the composition patterns of inorganic materials. Here we train a series of seven modern transformer language models (GPT, GPT-2, GPT-Neo, GPT-J, BLMM, BART, and RoBERTa) using the expanded formulas from material deposited in the ICSD, OQMD, and Materials Projects databases. Six different datasets with/out non-charge-neutral or balanced electronegativity samples are used to benchmark the performances and uncover the generation biases of modern transformer models for the generative design of materials compositions. Our extensive experiments showed that the causal language models based materials transformers can generate chemically valid materials compositions with as high as 97.54% to be charge neutral and 91.40% to be electronegativity balanced, which has more than 6 times higher enrichment compared to a baseline pseudo-random sampling algorithm. These models also demonstrate high novelty and their potential in new materials discovery has been proved by their capability to recover the leave-out materials. We also find that the properties of the generated samples can be tailored by training the models with selected training sets such as high-bandgap materials. Our experiments also showed that different models each have their own preference in terms of the properties of the generated samples and their running time complexity varies a lot. We have applied our materials transformer models to discover a set of new materials as validated using DFT calculations."}
{"title": "Quartet protein reference materials and datasets for multi-platform assessment of label-free proteomics", "abstract": "Background: Quantitative proteomics is an indispensable tool in life science research. However, there is a lack of reference materials for evaluating the reproducibility of label-free liquid chromatography-tandem mass spectrometry (LC–MS/MS)-based measurements among different instruments and laboratories. Results: Here, we develop the Quartet standard as a proteome reference material with built-in truths, and distribute the same aliquots to 15 laboratories with nine conventional LC–MS/MS platforms across six cities in China. Relative abundance of over 12,000 proteins on 816 mass spectrometry files are obtained and compared for reproducibility among the instruments and laboratories to ultimately generate proteomics benchmark datasets. There is a wide dynamic range of proteomes spanning about 7 orders of magnitude, and the injection order has marked effects on quantitative instead of qualitative characteristics. Conclusion: Overall, the Quartet offers valuable standard materials and data resources for improving the quality control of proteomic analyses as well as the reproducibility and reliability of research findings."}
{"title": "Machine Learning Models for the Lattice Thermal Conductivity Prediction of Inorganic Materials", "abstract": "The lattice thermal conductivity (κ_L) is a critical property of thermoelectrics, thermal barrier coating materials and semiconductors. While accurate empirical measurements of κ_L are extremely challenging, it is usually approximated through computational approaches, such as semi-empirical models, Green–Kubo formalism coupled with molecular dynamics simulations, and first-principles based methods. However, these theoretical methods are not only limited in terms of their accuracy, but sometimes become computationally intractable owing to their cost. Thus, in this work, we build a machine learning (ML)-based model to accurately and instantly predict κ_L of inorganic materials, using a benchmark data set of experimentally measured κ_L of about 100 inorganic solids. We use advanced and universal feature engineering techniques along with the Gaussian process regression algorithm, and compare the performance of our ML model with past theoretical works. The trained ML model is not only helpful for rational design and screening of novel materials, but we also identify key features governing the thermal transport behavior in non-metals."}
{"title": "Materials science optimization benchmark dataset for multi-objective, multi-fidelity optimization of hard-sphere packing simulations", "abstract": "In scientific disciplines, benchmarks play a vital role in driving progress forward. For a benchmark to be effective, it must closely resemble real-world tasks. If the level of difficulty or relevance is inadequate, it can impede progress in the field. Moreover, benchmarks should have low computational overhead to ensure accessibility and repeatability. The objective is to achieve a kind of “Turing test” by creating a surrogate model that is practically indistinguishable from the ground truth observation, at least within the dataset’s explored boundaries. This objective necessitates a large quantity of data. This data encompasses numerous features that are characteristic of chemistry and materials science optimization tasks that are relevant to industry. These features include high levels of noise, multiple fidelities, multiple objectives, linear constraints, non-linear correlations, and failure regions. We performed 494,498 random hard-sphere packing simulations representing 206 CPU days’ worth of computational overhead. Simulations required nine input parameters with linear constraints and two discrete fidelities each with continuous fidelity parameters. The results were logged in a free-tier shared MongoDB Atlas database, producing two core tabular datasets: a failure probability dataset and a regression dataset. The failure probability dataset maps unique input parameter sets to the estimated probabilities that the simulation will fail. The regression dataset maps input parameter sets (including repeats) to particle packing fractions and computational runtimes for each of the two steps. These two datasets were used to create a surrogate model as close as possible to running the actual simulations by incorporating simulation failure and heteroskedastic noise. In the regression dataset, percentile ranks were calculated for each group of identical parameter sets to account for heteroskedastic noise, thereby ensuring reliable and accurate data. This differs from the conventional approach that imposes a-priori assumptions, such as Gaussian noise, by specifying mean and standard deviation."}
{"title": "Material structure–property linkages using three-dimensional convolutional neural networks", "abstract": "In this paper, we develop an objective (data-driven) approach to efficiently and accurately link a three-dimensional (3-D) microstructure to its effective (homogenized) properties. Our method employs a 3-D convolutional neural network (CNN) to learn the salient features of the material microstructures that lead to good predictive performance for the effective property of interest. We then utilize 3-D CNN learned features as estimators of higher-order spatial correlations, and formulate an integrated framework combining 3-D CNN features with 2-point spatial correlations. The proposed framework is demonstrated on a dataset consisting of 3-D microstructures of two-phase composites with different volume fractions and topological characteristics. Our results show that the proposed framework can provide accurate and robust predictions of effective properties and offers a powerful tool for establishing structure–property linkages in heterogeneous materials."}
{"title": "Benchmarking graph neural networks for materials chemistry", "abstract": "Graph neural networks (GNNs) have received intense interest as a rapidly expanding class of machine learning models remarkably well-suited for materials applications. To date, a number of successful GNNs have been proposed and demonstrated for systems ranging from crystal stability to electronic property prediction and to surface chemistry and heterogeneous catalysis. However, a consistent benchmark of these models remains lacking, hindering the development and consistent evaluation of new models in the materials field. Here, we present a workflow and testing platform, MatDeepLearn, for quickly and reproducibly assessing and comparing GNNs and other machine learning models. We use this platform to optimize and evaluate a selection of top performing GNNs on several representative datasets in computational materials chemistry. From our investigations we note the importance of hyperparameter selection and find roughly similar performances for the top models once optimized. We identify several strengths in GNNs over conventional models in cases with compositionally diverse datasets and in its overall flexibility with respect to inputs, due to learned rather than defined representations. Meanwhile several weaknesses of GNNs are also observed including high data requirements, and suggestions for further improvement for applications in materials chemistry are discussed."}
{"title": "Benchmarking Machine Learning Models for Polymer Informatics: An Example of Glass Transition Temperature", "abstract": "In the field of polymer informatics, utilizing machine learning (ML) techniques to evaluate the glass transition temperature T_{g} and other properties of polymers has attracted extensive attention. This data-centric approach is much more efficient and practical than the laborious experimental measurements when encountered a daunting number of polymer structures. Various ML models are demonstrated to perform well for T_{g} prediction. Nevertheless, they are trained on different data sets, using different structure representations, and based on different feature engineering methods. Thus, the critical question arises on selecting a proper ML model to better handle the T_{g} prediction with generalization ability. To provide a fair comparison of different ML techniques and examine the key factors that affect the model performance, we carry out a systematic benchmark study by compiling 79 different ML models and training them on a large and diverse data set. The three major components in setting up an ML model are structure representations, feature representations, and ML algorithms. In terms of polymer structure representation, we consider the polymer monomer, repeat unit, and oligomer with longer chain structure. Based on that feature, representation is calculated, including Morgan fingerprinting with or without substructure frequency, RDKit descriptors, molecular embedding, molecular graph, etc. Afterward, the obtained feature input is trained using different ML algorithms, such as deep neural networks, convolutional neural networks, random forest, support vector machine, LASSO regression, and Gaussian process regression. We evaluate the performance of these ML models using a holdout test set and an extra unlabeled data set from high-throughput molecular dynamics simulation. The ML model's generalization ability on an unlabeled data set is especially focused, and the model's sensitivity to topology and the molecular weight of polymers is also taken into consideration. This benchmark study provides not only a guideline for the T_{g} prediction task but also a useful reference for other polymer informatics tasks."}
{"title": "Interpretable Deep-Learning pKa Prediction for Small Molecule Drugs via Atomic Sensitivity Analysis", "abstract": "Machine learning (ML) models now play a crucial role in predicting properties essential to drug development, such as a drug's logscale acid-dissociation constant (pK_{a}). Despite recent architectural advances, these models often generalize poorly to novel compounds due to a scarcity of ground-truth data. Further, these models lack interpretability. To this end, with deliberate molecular embeddings, atomic-resolution information is accessible in chemical structures by observing the model response to atomic perturbations of an input molecule. Here, we present BCL-XpKa, a deep neural network (DNN)-based multitask classifier for pK_{a} prediction that encodes local atomic environments through Mol2D descriptors. BCL-XpKa outputs a discrete distribution for each molecule, which stores the pK_{a} prediction and the model's uncertainty for that molecule. BCL-XpKa generalizes well to novel small molecules. BCL-XpKa performs competitively with modern ML pK_{a} predictors, outperforms several models in generalization tasks, and accurately models the effects of common molecular modifications on a molecule's ionizability. We then leverage BCL-XpKa's granular descriptor set and distribution-centered output through atomic sensitivity analysis (ASA), which decomposes a molecule's predicted pK_{a} value into its respective atomic contributions without model retraining. ASA reveals that BCL-XpKa has implicitly learned high-resolution information about molecular substructures. We further demonstrate ASA's utility in structure preparation for protein-ligand docking by identifying ionization sites in 93.2% and 87.8% of complex small molecule acids and bases. We then applied ASA with BCL-XpKa to identify and optimize the physicochemical liabilities of a recently published KRAS-degrading PROTAC."}
{"title": "Atom-Based Machine Learning for Estimating Nucleophilicity and Electrophilicity with Applications to Retrosynthesis and Chemical Stability", "abstract": "Nucleophilicity and electrophilicity are important properties for evaluating the reactivity and selectivity of chemical reactions. It allows the ranking of nucleophiles and electrophiles on reactivity scales, enabling a better understanding and prediction of reaction outcomes. Building upon our recent work (Digit. Discov., 2024, 3, 347-354), we introduce an atom-based machine learning (ML) approach for predicting methyl cation affinities (MCAs) and methyl anion affinities (MAAs) to estimate nucleophilicity and electrophilicity, respectively. The ML models are trained and validated on QM-derived data from around 50,000 neutral drug-like molecules, achieving Pearson correlation coefficients of 0.97 for MCA and 0.95 for MAA on the held-out test sets. In addition, we demonstrate the ML approach on two different applications: first, as a general tool for filtering retrosynthetic routes based on chemical selectivity predictions, and second, as a tool for assessing the chemical stability of esters and carbamates towards hydrolysis reactions. The code is freely available on GitHub under the MIT open source license and as a web application at www.esnuel.org."}
{"title": "Ab initio characterization of protein molecular dynamics with AI2BMD", "abstract": "Biomolecular dynamics simulation is a fundamental technology for life sciences research, and its usefulness depends on its accuracy and efficiency. Classical molecular dynamics simulation is fast but lacks chemical accuracy. Quantum chemistry methods such as density functional theory can reach chemical accuracy but cannot scale to support large biomolecules. Here we introduce an artificial intelligence-based ab initio biomolecular dynamics system (AI2BMD) that can efficiently simulate full-atom large biomolecules with ab initio accuracy. AI2BMD uses a protein fragmentation scheme and a machine learning force field to achieve generalizable ab initio accuracy for energy and force calculations for various proteins comprising more than 10,000 atoms, reducing computational time by several orders of magnitude compared to density functional theory. With several hundred nanoseconds of dynamics simulations, AI2BMD explores conformational space of peptides and proteins, derives accurate 3J couplings matching NMR experiments, shows folding/unfolding processes, and enables precise free-energy calculations aligned with experiments. AI2BMD could complement wet-lab experiments and enable biomedical research that is currently impractical."}
{"title": "An Open Quantum Chemistry Property Database of 120 Kilo Molecules with 20 Million Conformers", "abstract": "Artificial intelligence is revolutionizing computational chemistry, bringing unprecedented innovation and efficiency to the field. To further advance research and expedite progress, we introduce the Quantum Open Organic Molecular (QO2Mol) database—a large-scale quantum chemistry dataset designed for professional and transformative research in organic molecular sciences under an open-source license. The database comprises 120,000 organic molecules and approximately 20 million conformers, encompassing 10 different elements (C, H, O, N, S, P, F, Cl, Br, I), with heavy atom counts exceeding 40. Utilizing the high-precision B3LYP/def2-SVP quantum mechanical level, each conformation was computed for quantum mechanical properties, including potential energy and forces. These molecules are derived from fragments of compounds in ChEMBL, ensuring structural relevance to real-world compounds. Its extensive coverage of molecular structures and diverse elemental composition enables comprehensive studies of structure–property relationships, enhancing the accuracy and applicability of machine learning models in predicting molecular behaviors. The QO2Mol database and benchmark codes are available on GitHub."}
{"title": "Data-driven parametrization of molecular mechanics force fields for expansive chemical space coverage", "abstract": "A force field is a critical component in molecular dynamics simulations for computational drug discovery. It must achieve high accuracy within the constraints of molecular mechanics' (MM) limited functional forms, which offers high computational efficiency. With the rapid expansion of synthetically accessible chemical space, traditional look-up table approaches face significant challenges. In this study, we address this issue using a modern data-driven approach, developing ByteFF, an Amber-compatible force field for drug-like molecules. To create ByteFF, we generated an expansive and highly diverse molecular dataset at the B3LYP-D3(BJ)/DZVP level of theory. This dataset includes 2.4 million optimized molecular fragment geometries with analytical Hessian matrices, along with 3.2 million torsion profiles. We then trained an edge-augmented, symmetry-preserving molecular graph neural network (GNN) on this dataset, employing a carefully optimized training strategy. Our model predicts all bonded and non-bonded MM force field parameters for drug-like molecules simultaneously across a broad chemical space. ByteFF demonstrates state-of-the-art performance on various benchmark datasets, excelling in predicting relaxed geometries, torsional energy profiles, and conformational energies and forces. Its exceptional accuracy and expansive chemical space coverage make ByteFF a valuable tool for multiple stages of computational drug discovery."}
{"title": "Principles of isomer stability in small clusters", "abstract": "In this work we study isomers of several representative small clusters to find principles for their stability. Our conclusions about the principles underlying the structure of clusters are based on a huge database of 44,000 isomers generated for 58 different clusters on the density functional theory level by Minima Hopping. We explore the potential energy surface of small neutral, anionic and cationic isomers, moving left to right across the third period of the periodic table and varying the number of atoms n and the cluster charge state q (Xqn, with X = {Na, Mg, Al, Si, Ge}, q = −1, 0, 1, 2). We use structural descriptors such as bond lengths and atomic coordination numbers, the surface to volume ratios and the shape factor as well as electronic descriptors such as shell filling and hardness to detect correlations with the stability of clusters. The isomers of metallic clusters are found to be structure seekers with a strong tendency to adopt compact shapes. However certain numbers of atoms can suppress the formation of nearly spherical metallic clusters. Small non-metallic clusters typically also do not adopt compact spherical shapes for their lowest energy structures. In both cases spherical jellium models are not any more applicable. Nevertheless for many structures, that frequently have a high degree of symmetry, the Kohn–Sham eigenvalues are bunched into shells and if the available electrons can completely fill such shells, a particularly stable structure can result. We call such a cluster whose shape gives rise to shells that can be completely filled by the number of available electrons an optimally matched cluster, since both the structure and the number of electrons must be special and match. In this way we can also explain the stability trends for covalent silicon and germanium cluster isomers, whose stability was previously explained by the presence of certain structural motifs. Thus we propose a unified framework to explain trends in the stability of isomers and to predict their structure for a wide range of small clusters."}
{"title": "Using machine learning in QSPR to estimate the boiling and critical temperatures of pure organic compounds", "abstract": "This study aims to develop models using a Quantitative Structure–Property Relationship (QSPR) approach to predict normal boiling temperature (Tb) and critical temperature (Tc) for curated sets of organic compounds. Molecular descriptors derived from SMILES representations are combined with machine learning models, with multilayer perceptron artificial neural networks compared against support vector regression baselines. Models are trained and evaluated on datasets of roughly 400 compounds per property, and the best-performing configurations demonstrate improved predictive accuracy for both Tb and Tc relative to the SVR reference. The study discusses applicability domain assessment and sensitivity analyses of key descriptors, and highlights the potential of ML–QSPR frameworks for reliable estimation of thermophysical properties of pure organic compounds."}
